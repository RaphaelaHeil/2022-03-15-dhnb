{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2JV8Fagtg2e"
      },
      "source": [
        "# TF-IDF and cosine similarity\n",
        "Part one of this lesson is based on a tutorial that gives a more in-depth introduction to TF-IDF:<br>\n",
        "https://programminghistorian.org/en/lessons/analyzing-documents-with-tfidf\n",
        "\n",
        "Part two is an example of how lists of words weighted using TF-IDF can be used to calculate document similarity.\n",
        "\n",
        "**TF-IDF (term frequency-inverse document frequency)**:  A measure that can quantify the importance or relevance of words in a collection of documents<br>\n",
        "**Cosine similarity**: use geometry to calculate similarity between documents\n",
        "\n",
        "Python libraries\n",
        "- sklearn (machine learning)\n",
        "- nltk (natural language processing)\n",
        "- pandas (process tabular data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQ53DXJm2cvw",
        "outputId": "2f05d57e-107a-4610-8415-4eb2bc1af27c"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from collections import Counter\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!unzip lesson-files.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phr2dyA-onRL"
      },
      "source": [
        "## 1. TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1 Load text data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zW66L8A5epGT",
        "outputId": "687cbd34-c3b6-4184-f1d0-cf875ae9c52f"
      },
      "outputs": [],
      "source": [
        "# Get a list of the filenames\n",
        "input_files = os.listdir('lesson-files/txt')\n",
        "input_files.sort()\n",
        "input_files[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81taBdtLUmf4"
      },
      "outputs": [],
      "source": [
        "# Open the files and append their content to a list\n",
        "text_data = []\n",
        "for filename in input_files:\n",
        "  with open(\"lesson-files/txt/\" + filename) as input_file:\n",
        "    text = input_file.read()\n",
        "    text_data.append(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "pNDpZ4EhLmjm",
        "outputId": "6ef1043a-fba6-4309-ed5e-175cea30062a"
      },
      "outputs": [],
      "source": [
        "# Inspect the first 400 characters in the first document\n",
        "text_data[0][:400]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2 Tokenization: splitting text into words and punctutation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokens = text_data[0].split()\n",
        "Counter(tokens).most_common(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "HjGB9kx7N--N",
        "outputId": "e6e6419c-26db-4d4f-ec78-c44cd4b8c07a"
      },
      "outputs": [],
      "source": [
        "tokens = word_tokenize(text_data[0])\n",
        "Counter(tokens).most_common(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ys80Njd2of2h"
      },
      "source": [
        "### 1.3 TfidfVectorizer\n",
        "\n",
        "Parameters:<br>\n",
        "* <code>max_df=.65</code>: Ignore terms that appear in more than 65% of the documents\n",
        "* <code>min_df=1</code>: ignore words that occur in less than one document. The value must be higher than 1 for the parameter to have any effect\n",
        "* <code>stop_words</code>: manually list words that you want to ignore\n",
        "* <code>max_features</code>: limit the number of features (words)\n",
        "* <code>norm=None</code>: disable normalization (explained in the tutorial at Programming Historian)\n",
        "* <code>tokenizer=None</code>: Use default tokenization. This parameter allows us to override the tokenization process, for instance by using the tokenizer from nltk: <code>tokenizer=word_tokenize</code>\n",
        "\n",
        "Other possible parameters are listed in the documentation:<br>\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Guq5po6cfzYX"
      },
      "outputs": [],
      "source": [
        "# Create a vectorizer object and fit it to our data (calculate TF-IDF values)\n",
        "vectorizer = TfidfVectorizer(max_df=.65, min_df=1, stop_words=None, max_features=None, tokenizer=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fit the vectorizer to our data\n",
        "transformed_documents = vectorizer.fit_transform(text_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The TfidfVectorizer stores the calculated values in a sparse matrix - a list of lists that saves space in memory by only storing values other than zero. Non existing values are assumed to be zero."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gzr5NxmEWhU_",
        "outputId": "d617377b-5ac8-49d0-f45c-92a90fba8c35"
      },
      "outputs": [],
      "source": [
        "transformed_documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sustr5SUwWMf",
        "outputId": "33865c07-d9f3-431d-d1f9-afbd86fb2179"
      },
      "outputs": [],
      "source": [
        "# Sparse data: 285947  non-zero values across 13 million cells\n",
        "366 * 36269 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BQU-D3Bgew4",
        "outputId": "174d74e5-59ad-43eb-c303-d0c58cb1f7dc"
      },
      "outputs": [],
      "source": [
        "# Convert the sparse matrix to a regular table or array\n",
        "transformed_documents_as_array = transformed_documents.toarray()\n",
        "\n",
        "# Inspect the array and verify that it represents the same number of documents that we have in the file list\n",
        "feature_table = pd.DataFrame(transformed_documents_as_array, columns = vectorizer.get_feature_names())\n",
        "feature_table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etYITn9nh6lx"
      },
      "source": [
        "### 1.4 Read and write csv-files: Pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "6JuNMWNHhzUf",
        "outputId": "637adb89-65d9-49de-877d-57b83b51efb0"
      },
      "outputs": [],
      "source": [
        "metadata = pd.read_csv(\"lesson-files/metadata.csv\", index_col=0)\n",
        "metadata[:4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-E4Vr2sgw1m",
        "outputId": "78c3e7dd-7e04-4e2b-c732-b3ebf76508fe"
      },
      "outputs": [],
      "source": [
        "# Create output folder if it does not exist\n",
        "if not os.path.exists(\"tf_idf_output\"):\n",
        "    os.mkdir(\"tf_idf_output\")\n",
        "\n",
        "# loop each item from the list of input files and the array of transformed documents in parallel\n",
        "for filename, doc in zip(input_files, transformed_documents_as_array):\n",
        "  # convert the output to a dataframe\n",
        "  terms_and_scores = zip(vectorizer.get_feature_names(), doc)\n",
        "  one_doc_as_df = pd.DataFrame(terms_and_scores, columns = [\"term\", \"score\"]).sort_values(by='score', ascending=False)\n",
        "\n",
        "  # write the output to a csv\n",
        "  one_doc_as_df.to_csv(\"tf_idf_output/\" + filename.replace('txt', 'csv'), index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "tQBn1LyHllSj",
        "outputId": "bd5806b0-4837-4fa8-aaf6-16f85bee100c"
      },
      "outputs": [],
      "source": [
        "pd.read_csv(\"tf_idf_output/0101.csv\").head(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "CwakX6MfOSEt",
        "outputId": "b79ac343-2abf-43d7-abbb-a6a0f417d707"
      },
      "outputs": [],
      "source": [
        "pd.read_csv(\"tf_idf_output/0104.csv\").head(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-3Vv7mQNt13"
      },
      "outputs": [],
      "source": [
        "def load_terms(document_index, n = 4):\n",
        "  return pd.read_csv(\"tf_idf_output/\"+input_files[document_index].replace('txt', 'csv')).head(n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTSOmpGSgfl3"
      },
      "source": [
        "## 2.  Cosine similarity\n",
        "\n",
        "1. Treat the list of TF-IDF weighted values for each document as if they were dimensions in a physical space.\n",
        "2. Use the \"angle\" between two documents to calculate their similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "tcpovBI6ON71",
        "outputId": "23a62eda-39ef-4fb3-9977-9d5340366027"
      },
      "outputs": [],
      "source": [
        "# Create a table of similarities and display it as a dataframe\n",
        "similarities = cosine_similarity(transformed_documents)\n",
        "pd.DataFrame(similarities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8pLBupseg8p",
        "outputId": "7e825e5c-b604-4ef3-c574-73b3e24b4423"
      },
      "outputs": [],
      "source": [
        "# Sort the document indices by from low to high similarity\n",
        "similar_sorted = similarities[3].argsort()\n",
        "# Flip it (high to low similiarity)\n",
        "similar_sorted = np.flip(similar_sorted)\n",
        "# Inspect the first element (the index/position of the most similar document)\n",
        "similar_sorted[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List the indices of th top five most similar documents\n",
        "similar_docs = similar_sorted[1:6]\n",
        "similar_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "DFdjd9Hqb30q",
        "outputId": "82881c9c-c143-4b1c-84d9-f6ea97f2b6b5"
      },
      "outputs": [],
      "source": [
        "load_terms(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "Qar4GLHVckaz",
        "outputId": "5fbe6be1-bd43-4f37-a8eb-34e736179cb0"
      },
      "outputs": [],
      "source": [
        "load_terms(287)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "Ab7v8OcpcpHX",
        "outputId": "434ab836-da8c-48d9-d436-79b351339015"
      },
      "outputs": [],
      "source": [
        "# Filter the metadata table on the indices\n",
        "metadata.iloc[similar_docs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.set_option('display.max_rows', 30)\n",
        "load_terms(57, n=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "load_terms(0, n=30)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "TF-IDF_and_cosine_similarity.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
