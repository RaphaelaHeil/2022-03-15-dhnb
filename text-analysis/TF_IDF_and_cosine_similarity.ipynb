{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2JV8Fagtg2e"
   },
   "source": [
    "# TF-IDF and cosine similarity\n",
    "Part one of this lesson is based on a tutorial that gives a more in-depth introduction to TF-IDF:<br>\n",
    "https://programminghistorian.org/en/lessons/analyzing-documents-with-tfidf\n",
    "\n",
    "Part two is an example of how lists of words weighted using TF-IDF can be used to calculate document similarity.\n",
    "\n",
    "**TF-IDF (term frequency-inverse document frequency)**:  A measure that can quantify the importance or relevance of words in a collection of documents<br>\n",
    "**Cosine similarity**: use geometry to calculate similarity between documents\n",
    "\n",
    "Python libraries\n",
    "- sklearn (machine learning)\n",
    "- nltk (natural language processing)\n",
    "- pandas (process tabular data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IQ53DXJm2cvw",
    "outputId": "2f05d57e-107a-4610-8415-4eb2bc1af27c"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip lesson-files.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "phr2dyA-onRL"
   },
   "source": [
    "## 1. TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zW66L8A5epGT",
    "outputId": "687cbd34-c3b6-4184-f1d0-cf875ae9c52f"
   },
   "outputs": [],
   "source": [
    "# Get a list of the filenames\n",
    "input_files = os.listdir('lesson-files/txt')\n",
    "input_files.sort()\n",
    "input_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "81taBdtLUmf4"
   },
   "outputs": [],
   "source": [
    "# Open the files and append their content to a list\n",
    "text_data = []\n",
    "for filename in input_files:\n",
    "  with open(\"lesson-files/txt/\" + filename) as input_file:\n",
    "    text = input_file.read()\n",
    "    text_data.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "id": "pNDpZ4EhLmjm",
    "outputId": "6ef1043a-fba6-4309-ed5e-175cea30062a"
   },
   "outputs": [],
   "source": [
    "# Inspect the first 400 characters in the first document\n",
    "text_data[0][:400]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Tokenization: splitting text into words and punctutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = text_data[0].split()\n",
    "Counter(tokens).most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "HjGB9kx7N--N",
    "outputId": "e6e6419c-26db-4d4f-ec78-c44cd4b8c07a"
   },
   "outputs": [],
   "source": [
    "tokens = word_tokenize(text_data[0])\n",
    "Counter(tokens).most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ys80Njd2of2h"
   },
   "source": [
    "### 1.3 TfidfVectorizer\n",
    "\n",
    "Parameters:<br>\n",
    "* <code>max_df=.65</code>: Ignore terms that appear in more than 65% of the documents\n",
    "* <code>min_df=1</code>: ignore words that occur in less than one document. The value must be higher than 1 for the parameter to have any effect\n",
    "* <code>stop_words</code>: manually list words that you want to ignore\n",
    "* <code>max_features</code>: limit the number of features (words)\n",
    "* <code>norm=None</code>: disable normalization (explained in the tutorial at Programming Historian)\n",
    "* <code>tokenizer=None</code>: Use default tokenization. This parameter allows us to override the tokenization process, for instance by using the tokenizer from nltk: <code>tokenizer=word_tokenize</code>\n",
    "\n",
    "Other possible parameters are listed in the documentation:<br>\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Guq5po6cfzYX"
   },
   "outputs": [],
   "source": [
    "# Create a vectorizer object and fit it to our data (calculate TF-IDF values)\n",
    "vectorizer = TfidfVectorizer(max_df=.65, min_df=1, stop_words=None, max_features=None, tokenizer=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the vectorizer to our data\n",
    "transformed_documents = vectorizer.fit_transform(text_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TfidfVectorizer stores the calculated values in a sparse matrix - a list of lists that saves space in memory by only storing values other than zero. Non existing values are assumed to be zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gzr5NxmEWhU_",
    "outputId": "d617377b-5ac8-49d0-f45c-92a90fba8c35"
   },
   "outputs": [],
   "source": [
    "transformed_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sustr5SUwWMf",
    "outputId": "33865c07-d9f3-431d-d1f9-afbd86fb2179"
   },
   "outputs": [],
   "source": [
    "# Sparse data: 285947  non-zero values across 13 million cells\n",
    "366 * 36269 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9BQU-D3Bgew4",
    "outputId": "174d74e5-59ad-43eb-c303-d0c58cb1f7dc"
   },
   "outputs": [],
   "source": [
    "# Convert the sparse matrix to a regular table or array\n",
    "transformed_documents_as_array = transformed_documents.toarray()\n",
    "\n",
    "# Inspect the array and verify that it represents the same number of documents that we have in the file list\n",
    "feature_table = pd.DataFrame(transformed_documents_as_array, columns = vectorizer.get_feature_names())\n",
    "feature_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "etYITn9nh6lx"
   },
   "source": [
    "### 1.4 Read and write csv-files: Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "6JuNMWNHhzUf",
    "outputId": "637adb89-65d9-49de-877d-57b83b51efb0"
   },
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(\"lesson-files/metadata.csv\", index_col=0)\n",
    "metadata[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K-E4Vr2sgw1m",
    "outputId": "78c3e7dd-7e04-4e2b-c732-b3ebf76508fe"
   },
   "outputs": [],
   "source": [
    "# Create output folder if it does not exist\n",
    "if not os.path.exists(\"tf_idf_output\"):\n",
    "    os.mkdir(\"tf_idf_output\")\n",
    "\n",
    "# loop each item from the list of input files and the array of transformed documents in parallel\n",
    "for filename, doc in zip(input_files, transformed_documents_as_array):\n",
    "  # convert the output to a dataframe\n",
    "  terms_and_scores = zip(vectorizer.get_feature_names(), doc)\n",
    "  one_doc_as_df = pd.DataFrame(terms_and_scores, columns = [\"term\", \"score\"]).sort_values(by='score', ascending=False)\n",
    "\n",
    "  # write the output to a csv\n",
    "  one_doc_as_df.to_csv(\"tf_idf_output/\" + filename.replace('txt', 'csv'), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "tQBn1LyHllSj",
    "outputId": "bd5806b0-4837-4fa8-aaf6-16f85bee100c"
   },
   "outputs": [],
   "source": [
    "pd.read_csv(\"tf_idf_output/0101.csv\").head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "CwakX6MfOSEt",
    "outputId": "b79ac343-2abf-43d7-abbb-a6a0f417d707"
   },
   "outputs": [],
   "source": [
    "pd.read_csv(\"tf_idf_output/0104.csv\").head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B-3Vv7mQNt13"
   },
   "outputs": [],
   "source": [
    "def load_terms(document_index, n = 4):\n",
    "  return pd.read_csv(\"tf_idf_output/\"+input_files[document_index].replace('txt', 'csv')).head(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PTSOmpGSgfl3"
   },
   "source": [
    "## 2.  Cosine similarity\n",
    "\n",
    "1. Treat the list of TF-IDF weighted values for each document as if they were dimensions in a physical space.\n",
    "2. Use the \"angle\" between two documents to calculate their similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "tcpovBI6ON71",
    "outputId": "23a62eda-39ef-4fb3-9977-9d5340366027"
   },
   "outputs": [],
   "source": [
    "# Create a table of similarities and display it as a dataframe\n",
    "similarities = cosine_similarity(transformed_documents)\n",
    "pd.DataFrame(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b8pLBupseg8p",
    "outputId": "7e825e5c-b604-4ef3-c574-73b3e24b4423"
   },
   "outputs": [],
   "source": [
    "# Sort the document indices by from low to high similarity\n",
    "similar_sorted = similarities[3].argsort()\n",
    "# Flip it (high to low similiarity)\n",
    "similar_sorted = np.flip(similar_sorted)\n",
    "# Inspect the first element (the index/position of the most similar document)\n",
    "similar_sorted[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the indices of th top five most similar documents\n",
    "similar_docs = similar_sorted[1:6]\n",
    "similar_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "DFdjd9Hqb30q",
    "outputId": "82881c9c-c143-4b1c-84d9-f6ea97f2b6b5"
   },
   "outputs": [],
   "source": [
    "load_terms(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "Qar4GLHVckaz",
    "outputId": "5fbe6be1-bd43-4f37-a8eb-34e736179cb0"
   },
   "outputs": [],
   "source": [
    "load_terms(287)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "Ab7v8OcpcpHX",
    "outputId": "434ab836-da8c-48d9-d436-79b351339015"
   },
   "outputs": [],
   "source": [
    "# Filter the metadata table on the indices\n",
    "metadata.iloc[similar_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 30)\n",
    "load_terms(57, n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_terms(0, n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TF-IDF_and_cosine_similarity.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
